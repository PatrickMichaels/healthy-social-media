{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Analysis Model\n",
    "First we need the data for the model, the default corpus is a combination of several datasets. the resulting dataset is made of 500,000 comments, that are labelled as offensive or not offensive. \n",
    "Using this dataset we  need to convert into into a machine readable structure    \n",
    "We can use two representation methods, TF-IDF matrix and a Vector representation  \n",
    "TF-IDF will be more light weight, but Vector will be a stronger representation  \n",
    "Either way we will need to preprocess the text data of the combined dataset. This should be saved away for ease of use later as this dataset will not be changing once fully gathered and processed.  \n",
    "\n",
    "We want to split this dataset into a train and test set  \n",
    "Using this representation we can feed the train dataset to a libary implemented machine learning model and train it.   \n",
    "Then we can get a result for it's accurary by testing it with our test set.  \n",
    "We can also consider k-fold cross validation.  \n",
    "\n",
    "Several models can be tested to find the one which is most effective at this task. Models of note: K-NN, SVM, Neural Networks, BERT.   \n",
    "The Nerual Networks and BERT will be computationally expensive, consider running on the computer science clusters.  \n",
    "\n",
    "An Ensemble method can be created by leveraging the data that includes a target label. By creating a model for each of the given labels we can have a dedicated model for detecting a specific type of hate comment, which the hope is will be more sensetive to these types of comments then the general methods, as suggested by litreture. Then by combining these models in a larger model in an OR fashion or by using some form of model taking the results from it's constituent models as input we can then make the final decision.  This can also allow more transparcncy as to why things have been blocked or rejected, being able to state this comment is suspected to be racist, or has been flagged as sexist etc. Therefore we can inform the user what the moderation has detected so that may make changes to their behaviour.  \n",
    "\n",
    "We choose to reject or accept, or recommend for human moderation, a comment based on the confidence that the model has with it's classification. that is to say how close to a decision boundary that comment falls. Comments with high confidence can be accepted or rejected straight away. Those that are more uncertain, e.g. has a 54% confidence, can be copyed and sent to a queue for a human moderator to deal with. How these messages are dealt with is up to the developer, be they posted until moderated or hidden until moderated is up to them. This will be a very platform dependent choice.   \n",
    "Additionally the confidence threshold can be set depending on how much a developer trusts the model, the number of human resources they have to dedicate to moderation, the size of their platform, etc.  \n",
    "\n",
    "Finally functionality for a developer given dataset should be given so that they can use this to create their own models relatively robustly. It should be sufficent for a CVS file with 3 fields, Comment, Class, Target. Comment being the text in question, the Class being the binary class of if this is offensive or not, and Target being who an offensive comment is targeted at, N/A if target models are not wanted to be used. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration ucberkeley-dlab--measuring-hate-speech-7cb9b0b8e4d0e1dd\n",
      "Reusing dataset parquet (/dcs/18/u1801796/.cache/huggingface/datasets/parquet/ucberkeley-dlab--measuring-hate-speech-7cb9b0b8e4d0e1dd/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n",
      "100%|██████████| 1/1 [00:00<00:00, 137.05it/s]\n"
     ]
    }
   ],
   "source": [
    "#Preprocess our 23 datasets here to strip them down to Comment, Class, Target\n",
    "\n",
    "#Downloads the berkley dataset to be cleaned.\n",
    "import datasets\n",
    "#import pickle\n",
    "dataset = datasets.load_dataset('ucberkeley-dlab/measuring-hate-speech', 'binary') \n",
    "df = dataset['train'].to_pandas()\n",
    "\n",
    "'''\n",
    "#TODO\n",
    "#I'll leave this for now as it's only needed for the ensemble methods.\n",
    "#Coallate the targets of a comment into a single array\n",
    "for i in range(len(df)):\n",
    "    #TODO investigate this threshold for True or falsing this\n",
    "    if df.loc[i,\"hate_speech_score\"] <= 0:\n",
    "        df.loc[i,\"hate_speech_score\"] = 0\n",
    "    else:\n",
    "        df.loc[i,\"hate_speech_score\"] = 1\n",
    "'''\n",
    "\n",
    "\n",
    "#Convert the hate_speech_score into a true or a false\n",
    "for i in range(len(df)):\n",
    "    #TODO investigate this threshold for True or falsing this\n",
    "    if df.loc[i,\"hate_speech_score\"] <= 0:\n",
    "        df.loc[i,\"hate_speech_score\"] = 0\n",
    "    else:\n",
    "        df.loc[i,\"hate_speech_score\"] = 1\n",
    "# our attributes are df['text'] df['hate_speech_score'] Turned into a class, and df['targets'] saved into an array of targets, rather than seperate attributes\n",
    "df_to_save=df[['text','hate_speech_score']]\n",
    "#df_to_save.to_pickle(\"/berkely_dataset.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 20636)\t0.06106529043188453\n",
      "  (0, 20768)\t0.07254358471739625\n",
      "  (0, 43528)\t0.09465989304554864\n",
      "  (0, 25074)\t0.16472803269372016\n",
      "  (0, 27820)\t0.09060787035598802\n",
      "  (0, 32188)\t0.15498267675024005\n",
      "  (0, 28945)\t0.09810787025087804\n",
      "  (0, 36217)\t0.09720682414376836\n",
      "  (0, 43326)\t0.08424704034455922\n",
      "  (0, 31645)\t0.27655184631499136\n",
      "  (0, 4429)\t0.14642653526697447\n",
      "  (0, 44153)\t0.10965929642599052\n",
      "  (0, 2203)\t0.12283829282330892\n",
      "  (0, 32726)\t0.12384620639620078\n",
      "  (0, 9357)\t0.21126208600131477\n",
      "  (0, 40478)\t0.051374867467332073\n",
      "  (0, 43155)\t0.15584652000457389\n",
      "  (0, 17952)\t0.08013881160992473\n",
      "  (0, 44155)\t0.1680893015717001\n",
      "  (0, 2447)\t0.05136744978820325\n",
      "  (0, 38208)\t0.18253484776839066\n",
      "  (0, 18223)\t0.10282057835984945\n",
      "  (0, 39574)\t0.18361241265727132\n",
      "  (0, 43225)\t0.10735852939038852\n",
      "  (0, 43667)\t0.1927390499656514\n",
      "  :\t:\n",
      "  (122393, 45138)\t1.0\n",
      "  (122394, 45138)\t1.0\n",
      "  (122395, 45138)\t1.0\n",
      "  (122396, 45138)\t1.0\n",
      "  (122398, 45138)\t1.0\n",
      "  (122399, 45138)\t1.0\n",
      "  (122400, 45138)\t1.0\n",
      "  (122405, 45138)\t1.0\n",
      "  (122406, 45138)\t1.0\n",
      "  (122407, 45138)\t1.0\n",
      "  (122408, 45138)\t1.0\n",
      "  (122411, 45138)\t1.0\n",
      "  (122414, 45138)\t1.0\n",
      "  (122415, 45138)\t1.0\n",
      "  (122416, 45138)\t1.0\n",
      "  (122418, 45138)\t1.0\n",
      "  (122423, 45138)\t1.0\n",
      "  (122426, 45138)\t1.0\n",
      "  (122427, 45138)\t1.0\n",
      "  (122428, 45138)\t1.0\n",
      "  (122429, 45138)\t1.0\n",
      "  (122430, 45138)\t1.0\n",
      "  (122431, 45138)\t1.0\n",
      "  (122432, 45138)\t1.0\n",
      "  (122434, 45138)\t1.0\n"
     ]
    }
   ],
   "source": [
    "#Take in our combined dataset, in format, Comment, Class, Target and focus on the Comment attribute\n",
    "#Preprocess comment into a computer readable string representation, either TF-IDF or Vector, should be allowed for either to be used.\n",
    "# Should be able to deal with any dataset of Comment, Binary Class, Target representation to allow developer to input their own dataset\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "import numpy as np\n",
    "\n",
    "#TODO combine the class back to the tfidf matrix\n",
    "def preprocess_dataset(dataset):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    #construct the corpus, all the text\n",
    "    corpus=dataset['text']\n",
    "    #pass to the TF-IDF vectorizer to create a normalised tf-idf matrix\n",
    "    X = vectorizer.fit_transform(corpus) \n",
    "    # Recombine with the classes and labels from dataset \n",
    "    #TODO this right\n",
    "\n",
    "    X=hstack((X,dataset[['hate_speech_score']]))\n",
    "    return X\n",
    "+\n",
    "#print(df_to_save[['hate_speech_score']].shape)\n",
    "X=preprocess_dataset(df_to_save)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a dataset of Preprocessed Text, Binary Class, Target\n",
    "# Train some models, KNN, vs SVM\n",
    "# If Target us not N/A for all then we can build a model for each Target, store the models in an array, then we can use these as a feature vector or just OR the results of is confidence>Threshold for all modules.\n",
    "def train_model(dataset):\n",
    "    pass\n",
    "\n",
    "def train_models(dataset):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
